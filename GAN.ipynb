{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1dbfce9",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# Generator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b4d4dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import sys\n",
    "import numpy as np\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "block_size = 128\n",
    "num_blocks=4\n",
    "\n",
    "\n",
    "generator = Sequential()\n",
    "generator.add(Dense(block_size, input_shape=(100, )))\n",
    "generator.add(LeakyReLU(alpha=0.02))\n",
    "generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "for i in range(num_blocks-1):\n",
    "    block_size = block_size * 2\n",
    "    generator.add(Dense(block_size))\n",
    "    generator.add(LeakyReLU(alpha=0.2))\n",
    "    generator.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "generator.add(Dense(28 * 28 * 1, activation='tanh'))\n",
    "generator.add(Reshape((28, 28, 1)))\n",
    "generator.compile(loss=\"binary_crossentropy\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e49c141",
   "metadata": {},
   "source": [
    "# Discriminator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9507a877",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "from keras.layers import Input, Dense, Reshape, Flatten, Dropout\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "\n",
    "SHAPE =  (28, 28, 1)\n",
    "CAPACITY = 28 * 28 * 1\n",
    "\n",
    "\n",
    "discriminator = Sequential()\n",
    "discriminator.add(Flatten(input_shape = SHAPE))\n",
    "discriminator.add(Dense(CAPACITY, input_shape=SHAPE))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dense(int(CAPACITY/2)))\n",
    "discriminator.add(LeakyReLU(alpha=0.2))\n",
    "discriminator.add(Dense(1, activation='sigmoid'))\n",
    "discriminator.compile(loss=\"binary_crossentropy\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e854944",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 392)               307720    \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 392)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 393       \n",
      "=================================================================\n",
      "Total params: 923,553\n",
      "Trainable params: 923,553\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ac838",
   "metadata": {},
   "source": [
    "# GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad100224",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GAN\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan = Sequential()\n",
    "gan.add(generator)\n",
    "gan.add(discriminator)\n",
    "gan.compile(loss=\"binary_crossentropy\", optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028d7311",
   "metadata": {},
   "source": [
    "# load mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18d168f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = -1\n",
    "def load_MNIST(model_type):\n",
    "\n",
    "    allowed_types = [-1,0,1,2,3,4,5,6,7,8,9]\n",
    "\n",
    "    if model_type not in allowed_types:\n",
    "        print('ERROR: Only Integer Values from -1 to 9 are allowed')\n",
    "\n",
    "    (X_train, Y_train), (_, _) = mnist.load_data()\n",
    "    \n",
    "    xxx = X_train\n",
    "#     print(\"X_train: \", X_train.shape)\n",
    "    if model_type!=-1:\n",
    "        X_train = X_train[np.where(Y_train==int(model_type)) [0]]\n",
    "        print(\"X_train: \", X_train.shape)\n",
    "\n",
    "    X_train = ( np.float32(X_train) - 127.5) / 127.5\n",
    "#     X_train = np.expand_dims(X_train, axis=3)\n",
    "    \n",
    "    return X_train, Y_train, xxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca07565d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'mnist' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-c2066289d722>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_MNIST\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-8-b2b7c59a4e0e>\u001b[0m in \u001b[0;36mload_MNIST\u001b[1;34m(model_type)\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'ERROR: Only Integer Values from -1 to 9 are allowed'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mxxx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'mnist' is not defined"
     ]
    }
   ],
   "source": [
    "X_train, Y_train, xxx = load_MNIST(model_type=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fb96351",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imshow(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8ac2c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "\n",
    "# Grab a batch\n",
    "count_real_images = int(32/2)\n",
    "starting_index = randint(0, (len(X_train) - count_real_images ))\n",
    "starting_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cc6b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_images_raw = X_train[starting_index : (starting_index + count_real_images)]\n",
    "real_images_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb067a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = plt.imshow(real_images_raw[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43042b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_real_images = real_images_raw.reshape(count_real_images, 28, 28, 1)\n",
    "x_real_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee2c15",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real_lebels = np.ones([count_real_images, 1])\n",
    "y_real_lebels.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363fdaf6",
   "metadata": {},
   "source": [
    "# Grab Generated Images for this training batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0237cec",
   "metadata": {},
   "outputs": [],
   "source": [
    "LATENT_SPACE_SIZE = 100\n",
    "def sample_latent_space(instances):\n",
    "        return np.random.normal(0, 1, (instances, LATENT_SPACE_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e395612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab Generated Images for this training batch\n",
    "latent_space_samples = sample_latent_space(count_real_images)\n",
    "latent_space_samples.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52360697",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_generated_images = generator.predict(latent_space_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f1c5a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_generated_labels = np.zeros([32-count_real_images,1])\n",
    "y_generated_labels.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd20f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(y_generated_labels[0], y_real_lebels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3455ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine to train on the discriminator\n",
    "x_batch = np.concatenate( [x_real_images, x_generated_images] )\n",
    "y_batch = np.concatenate( [y_real_lebels, y_generated_labels] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03fdf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2db7c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch[16]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4a7e38",
   "metadata": {},
   "source": [
    "# Train Adversarial Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dccc0da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, train the discriminator with this batch\n",
    "discriminator_loss = discriminator.train_on_batch(x_batch,y_batch)\n",
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaf5490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate Noise\n",
    "x_latent_space_samples = sample_latent_space(32)\n",
    "y_generated_labels = np.ones([32,1])\n",
    "y_generated_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db00231b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generator_loss = gan.train_on_batch(x_latent_space_samples, y_generated_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18145615",
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('Epoch: '+str(int(1))+', [Discriminator :: Loss:'+str(discriminator_loss)+'], [ Generator :: Loss:'+str(generator_loss)+']')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae54059",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e6dec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
